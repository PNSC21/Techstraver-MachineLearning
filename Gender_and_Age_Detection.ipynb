{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = 'models/opencv_face_detector_uint8.pb'\n",
    "face_proto = 'models/opencv_face_detector.pbtxt'\n",
    "age_model = 'models/age_net.caffemodel'\n",
    "age_proto = 'models/age_deploy.prototxt'\n",
    "gender_model = 'models/gender_net.caffemodel'\n",
    "gender_proto = 'models/gender_deploy.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_net = cv2.dnn.readNet(face_model, face_proto)\n",
    "age_net = cv2.dnn.readNet(age_model, age_proto)\n",
    "gender_net = cv2.dnn.readNet(gender_model, gender_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_LIST = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "GENDER_LIST = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Task2_img'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.webp'):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to read image '{image_path}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        (h, w) = image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "\n",
    "        # Detect faces\n",
    "        face_net.setInput(blob)\n",
    "        detections = face_net.forward()\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.7:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                face = image[startY:endY, startX:endX]\n",
    "                face_blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), [78.4263377603, 87.7689143744, 114.895847746], swapRB=False)\n",
    "\n",
    "                # Predict gender\n",
    "                gender_net.setInput(face_blob)\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = GENDER_LIST[gender_preds[0].argmax()]\n",
    "\n",
    "                # Predict age\n",
    "                age_net.setInput(face_blob)\n",
    "                age_preds = age_net.forward()\n",
    "                age = AGE_LIST[age_preds[0].argmax()]\n",
    "\n",
    "                # Draw the bounding box and label on the image\n",
    "                label = f'{gender}, {age}'\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                cv2.putText(image, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\n",
    "        resized_image = cv2.resize(image, (850, 900))  # Adjust the size as needed\n",
    "\n",
    "        # Display the output image\n",
    "        cv2.imshow('Output', resized_image)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
